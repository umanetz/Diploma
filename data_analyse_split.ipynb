{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from itertools import combinations\n",
    "import collections\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 15:35:45.648100 139755243960128 file_utils.py:41] PyTorch version 1.2.0 available.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, BertModel, BertTokenizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FILE = './files/data/processed_08_04.npy'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кол-во примеров: 147636, кол-во классов 291\n"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame(np.load(DATA_FILE), columns=['y','words','text_y'])\n",
    "print(f'Кол-во примеров: {data.shape[0]}, кол-во классов {len(set(data[\"y\"]))}') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1) Удаляем дубликаты**  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 15 классов\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15     10761\n",
       "12      8873\n",
       "9       8173\n",
       "14      8118\n",
       "271     5778\n",
       "20      5392\n",
       "16      5099\n",
       "2       4369\n",
       "6       4239\n",
       "7       4239\n",
       "1       3914\n",
       "22      3410\n",
       "21      3209\n",
       "11      3101\n",
       "48      2785\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['sentence'] = data['words'].apply(lambda x: ' '.join(x))\n",
    "data = data.drop_duplicates(subset=['sentence','y'])\n",
    "print('Top 15 классов')\n",
    "class_count = data['y'].value_counts()\n",
    "class_count[:15]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) Удаляем примеры нулевой длины**  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "кол-во предложений с длиной 0: 12\n"
     ]
    }
   ],
   "source": [
    "print(f\"кол-во предложений с длиной 0: {data['words'].apply(lambda x: len(x)==0).sum()}\")\n",
    "data = data[data['words'].apply(lambda x: len(x) > 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заметим, что предложения не уникальны. Одно и тоже предложение может принадлежать разным классам.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кол-во уникальных предложений: 94595\n",
      "Какое кол-во разных классов может приходится на 1 предложение\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1     71601\n",
       "2     10128\n",
       "3      4942\n",
       "4      4048\n",
       "5      2132\n",
       "6       996\n",
       "7       471\n",
       "8       154\n",
       "9        60\n",
       "10       47\n",
       "12        6\n",
       "11        4\n",
       "21        2\n",
       "13        1\n",
       "66        1\n",
       "19        1\n",
       "22        1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Кол-во уникальных предложений: {len(data['sentence'].unique())}\")\n",
    "print('Какое кол-во разных классов может приходится на 1 предложение')\n",
    "x = data.groupby('sentence')['y'].apply(lambda x: len(set(x)))\n",
    "pd.value_counts(x.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что больше 20К предложений имеют 2 и более класса. Удалим примеры с 6 и более классами. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_target = data.groupby(['sentence'])['y'].apply(lambda x: list(set(x))).reset_index()\n",
    "sentence_target = sentence_target[sentence_target['y'].apply(lambda x: len(x) < 6)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4) Если одно предложение относится к разным классам, то выбираем наиболее популярный класс**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>y</th>\n",
       "      <th>true_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>action plans mis отсутствовать возможность вно...</td>\n",
       "      <td>[153]</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>android телефон клиент подвергнуться мошенниче...</td>\n",
       "      <td>[51]</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aс екс кредитный договор автоматический режим ...</td>\n",
       "      <td>[48, 50, 124]</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bankhelper представлять трудность однозначно в...</td>\n",
       "      <td>[48]</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cccp tomsk mail ru просить скорректировать рол...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence              y  true_y\n",
       "0  action plans mis отсутствовать возможность вно...          [153]     153\n",
       "1  android телефон клиент подвергнуться мошенниче...           [51]      51\n",
       "2  aс екс кредитный договор автоматический режим ...  [48, 50, 124]      48\n",
       "3  bankhelper представлять трудность однозначно в...           [48]      48\n",
       "4  cccp tomsk mail ru просить скорректировать рол...            [1]       1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_target['true_y'] = sentence_target['y'].apply(lambda x: class_count.loc[x].sort_values().index[-1] \n",
    "                                                       if len(x) > 1 else x[0])\n",
    "sentence_target.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5) Все классы с кол-вом примеров меньше 200 объединим в один класс.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего классов: 287, кол-во класов с меньше 200 примерами 208\n",
      "Доля примеров, которые объединяются в 1 класс 0.09543246707089853\n"
     ]
    }
   ],
   "source": [
    "class_count = sentence_target['true_y'].value_counts()\n",
    "rare_calsses = class_count.index[class_count < 200]\n",
    "print(f'Всего классов: {class_count.shape[0]}, кол-во класов с меньше 200 примерами {rare_calsses.shape[0]}')\n",
    "print('Доля примеров, которые объединяются в 1 класс',\n",
    "      class_count[class_count < 200].sum() / sum(class_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>y</th>\n",
       "      <th>true_y</th>\n",
       "      <th>common_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>action plans mis отсутствовать возможность вно...</td>\n",
       "      <td>[153]</td>\n",
       "      <td>153</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>android телефон клиент подвергнуться мошенниче...</td>\n",
       "      <td>[51]</td>\n",
       "      <td>51</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aс екс кредитный договор автоматический режим ...</td>\n",
       "      <td>[48, 50, 124]</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bankhelper представлять трудность однозначно в...</td>\n",
       "      <td>[48]</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cccp tomsk mail ru просить скорректировать рол...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence              y  true_y  \\\n",
       "0  action plans mis отсутствовать возможность вно...          [153]     153   \n",
       "1  android телефон клиент подвергнуться мошенниче...           [51]      51   \n",
       "2  aс екс кредитный договор автоматический режим ...  [48, 50, 124]      48   \n",
       "3  bankhelper представлять трудность однозначно в...           [48]      48   \n",
       "4  cccp tomsk mail ru просить скорректировать рол...            [1]       1   \n",
       "\n",
       "   common_y  \n",
       "0        -1  \n",
       "1        -1  \n",
       "2        48  \n",
       "3        48  \n",
       "4         1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_target['common_y'] = sentence_target['true_y'].apply(lambda x: -1 if x in rare_calsses else x)\n",
    "sentence_target.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Определяем максимальную длину последовательности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sent_len = []\n",
    "for sample in (sentence_target['sentence']):\n",
    "    sent_len.append(len(sample.split()))\n",
    "sent_len = np.array(sent_len)\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.hist(np.log10(sent_len[sent_len!=0]));\n",
    "# plt.xticks(range(7), [int(np.exp(i)) for i in range(7)]);\n",
    "plt.xticks([0, 1, 2, 3], ['$10^0$', '$10^1$','$10^2$', '$10^3$']);\n",
    "\n",
    "# # plt.title('Длина текста (в словах)')\n",
    "#  log = True\n",
    "# plt.hist(sent_len[sent_len!=0], bins=20);\n",
    "# plt.xscale('log')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98% примеров имеют длину текста <= 100 + 2 токена для начала и конца\n"
     ]
    }
   ],
   "source": [
    "print(f'98% примеров имеют длину текста <= {np.percentile(sent_len, 98):.0f} + 2 токена для начала и конца')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 102"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Поделим на Train, Dev, Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55710, 4) (18570, 4) (18571, 4)\n"
     ]
    }
   ],
   "source": [
    "strat = sentence_target['common_y'].values\n",
    "train_data, test_data = train_test_split(sentence_target, test_size=0.4, random_state=42, stratify=strat)\n",
    "test_data, dev_data = train_test_split(test_data, test_size=0.5, random_state=42)\n",
    "\n",
    "print(train_data.shape, test_data.shape, dev_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Все классы переводим в диапазон от 0 до кол-ва классов**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кол-во классов 80\n"
     ]
    }
   ],
   "source": [
    "target_mapping = pd.value_counts(train_data['common_y'])\n",
    "target_mapping = dict(zip(target_mapping.index, range(len(target_mapping))))\n",
    "num_classes = len(target_mapping)\n",
    "print('Кол-во классов', num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kate/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "train_data['target'] = train_data['common_y'].apply(lambda x: target_mapping[x])\n",
    "test_data['target'] = test_data['common_y'].apply(lambda x: target_mapping[x])\n",
    "dev_data['target'] = dev_data['common_y'].apply(lambda x: target_mapping[x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kate/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>y</th>\n",
       "      <th>true_y</th>\n",
       "      <th>common_y</th>\n",
       "      <th>target</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19958</th>\n",
       "      <td>заявка возвратить доработка следующий причина ...</td>\n",
       "      <td>[14]</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38980</th>\n",
       "      <td>клиент обратиться уточнение информация защита ...</td>\n",
       "      <td>[271]</td>\n",
       "      <td>271</td>\n",
       "      <td>271</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>cлучай отсутствие резервный копия криптоключ у...</td>\n",
       "      <td>[67]</td>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22256</th>\n",
       "      <td>заявка возвратить доработка следующий причина ...</td>\n",
       "      <td>[14]</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75734</th>\n",
       "      <td>расхождение мпп мотивационный калькулятор</td>\n",
       "      <td>[41]</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence      y  true_y  \\\n",
       "19958  заявка возвратить доработка следующий причина ...   [14]      14   \n",
       "38980  клиент обратиться уточнение информация защита ...  [271]     271   \n",
       "28     cлучай отсутствие резервный копия криптоключ у...   [67]      67   \n",
       "22256  заявка возвратить доработка следующий причина ...   [14]      14   \n",
       "75734          расхождение мпп мотивационный калькулятор   [41]      41   \n",
       "\n",
       "       common_y  target  id  \n",
       "19958        14       3   0  \n",
       "38980       271       2   1  \n",
       "28           67      56   2  \n",
       "22256        14       3   3  \n",
       "75734        41      10   4  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['id'] = np.arange(len(train_data))\n",
    "test_data['id'] = np.arange(len(test_data))\n",
    "dev_data['id'] = np.arange(len(dev_data))\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Формирование выборок для LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраняем преобразованные в набор индексов предложения train, test, dev в папку 'files/data/tokens/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _build_vocab(data):\n",
    "    counter = collections.Counter()\n",
    "    for sample in data['sentence']:\n",
    "        counter.update(collections.Counter(sample.split()))\n",
    "    count_pairs = sorted(counter.items(), key=lambda x: (-x[1], x[0]))\n",
    "\n",
    "    words, _ = list(zip(*count_pairs))\n",
    "    word_to_id = dict(zip(words, range(1, len(words)+1)))\n",
    "    word_to_id['PAD'] = 0\n",
    "    return word_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_id = _build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_by_tokens(data, word_to_id):\n",
    "    data_tokens = []\n",
    "    targets = []\n",
    "    idx = []\n",
    "    \n",
    "    for i, sample in data.iterrows():\n",
    "        sent = sample['sentence']\n",
    "        target = sample['target']\n",
    "        idx.append(sample['id'])\n",
    "        tokens = [word_to_id[x] for x in sent.split() if x in word_to_id][:MAX_LEN]\n",
    "        tokens = tokens + [word_to_id['PAD']] * (MAX_LEN - len(tokens))\n",
    "        \n",
    "        data_tokens.append(tokens)\n",
    "        targets.append(target)\n",
    "    df = pd.DataFrame(data_tokens)    \n",
    "    df['target'] = targets\n",
    "    df['id'] = idx\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokens_train = split_by_tokens(train_data, word_to_id)\n",
    "tokens_test = split_by_tokens(test_data, word_to_id)\n",
    "tokens_dev = split_by_tokens(dev_data, word_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>target</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>218</td>\n",
       "      <td>73</td>\n",
       "      <td>6</td>\n",
       "      <td>80</td>\n",
       "      <td>25547</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>225</td>\n",
       "      <td>13</td>\n",
       "      <td>924</td>\n",
       "      <td>441</td>\n",
       "      <td>7</td>\n",
       "      <td>418</td>\n",
       "      <td>1247</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1    2   3    4    5   6    7     8      9  ...  94  95  96  97  98  \\\n",
       "0  2  21   20  16    9  218  73    6    80  25547  ...   0   0   0   0   0   \n",
       "1  1  32  225  13  924  441   7  418  1247     26  ...   0   0   0   0   0   \n",
       "\n",
       "   99  100  101  target  id  \n",
       "0   0    0    0       3   0  \n",
       "1   0    0    0       2   1  \n",
       "\n",
       "[2 rows x 104 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'files/data/'\n",
    "lstm_data_path = data_path + 'tokens/'\n",
    "\n",
    "os.makedirs(lstm_data_path, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_train.to_csv(lstm_data_path + 'tokens_train.csv', index=False)\n",
    "tokens_test.to_csv(lstm_data_path + 'tokens_test.csv', index=False)\n",
    "tokens_dev.to_csv(lstm_data_path + 'tokens_dev.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "json.dump(word_to_id, open(data_path + 'word_to_id.json', 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Формирование выборок для Bert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Каждое предложение токенизируем с помощью BertTokenizer, заполняем 0 до максимальной длинны, считаем маску и сохраняем в 'files/data/bert_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification, BertModel, BertTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 15:36:30.532302 139755243960128 tokenization_utils.py:420] Model name './files/bert/rubert_cased_L-12_H-768_A-12_pt/' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming './files/bert/rubert_cased_L-12_H-768_A-12_pt/' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "I0509 15:36:30.533077 139755243960128 tokenization_utils.py:449] Didn't find file ./files/bert/rubert_cased_L-12_H-768_A-12_pt/added_tokens.json. We won't load it.\n",
      "I0509 15:36:30.533645 139755243960128 tokenization_utils.py:449] Didn't find file ./files/bert/rubert_cased_L-12_H-768_A-12_pt/special_tokens_map.json. We won't load it.\n",
      "I0509 15:36:30.534165 139755243960128 tokenization_utils.py:449] Didn't find file ./files/bert/rubert_cased_L-12_H-768_A-12_pt/tokenizer_config.json. We won't load it.\n",
      "I0509 15:36:30.534579 139755243960128 tokenization_utils.py:502] loading file ./files/bert/rubert_cased_L-12_H-768_A-12_pt/vocab.txt\n",
      "I0509 15:36:30.534919 139755243960128 tokenization_utils.py:502] loading file None\n",
      "I0509 15:36:30.535295 139755243960128 tokenization_utils.py:502] loading file None\n",
      "I0509 15:36:30.535601 139755243960128 tokenization_utils.py:502] loading file None\n"
     ]
    }
   ],
   "source": [
    "BERT_PATH = './files/bert/rubert_cased_L-12_H-768_A-12_pt/'\n",
    "tokenizer = BertTokenizer.from_pretrained(BERT_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset_bert(data):\n",
    "    ids_target = []\n",
    "    for i, sample in data.iterrows():\n",
    "        sent = sample['sentence']\n",
    "        t = sample['target']\n",
    "        encoded_dict = tokenizer.encode_plus(\n",
    "                        sent,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = MAX_LEN,           # Pad & truncate all sentences.\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                   )\n",
    "        encoded_dict['input_ids'] = encoded_dict['input_ids'][0]\n",
    "        encoded_dict['token_type_ids'] = encoded_dict['token_type_ids'][0]\n",
    "        encoded_dict['attention_mask'] = encoded_dict['attention_mask'][0]\n",
    "        \n",
    "        sample_info = {'sent': sent,\n",
    "                       'data': encoded_dict,\n",
    "                        'target' : t,\n",
    "                      'id': sample['id']}\n",
    "        ids_target.append(sample_info)\n",
    "    return ids_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_data_train = make_dataset_bert(train_data)\n",
    "bert_data_test = make_dataset_bert(test_data)\n",
    "bert_data_dev = make_dataset_bert(dev_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_data_path = data_path + 'bert_data/'\n",
    "os.makedirs(bert_data_path, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(bert_data_path + 'train.npy', bert_data_train)\n",
    "np.save(bert_data_path + 'test.npy', bert_data_test)\n",
    "np.save(bert_data_path + 'dev.npy', bert_data_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
